# 4. Intelig√™ncia Artificial Generativa (IA Generativa)



**IA Generativa** √© um ramo da Intelig√™ncia Artificial que utiliza modelos estat√≠sticos para aprender a distribui√ß√£o dos dados e gerar novos conte√∫dos com caracter√≠sticas semelhantes aos dados de treinamento.

Diferente de muitos sistemas de IA voltados para classifica√ß√£o ou previs√£o, a IA generativa tem como objetivo produzir novos dados semelhantes aos exemplos observados.

> N√£o √© s√≥ uma IA que responde ‚Äî √© uma IA que **cria como um artista, escritor ou programador**.

### Exemplos reais

- ChatGPT (texto e c√≥digo)
- Midjourney / DALL¬∑E (imagens)
- GitHub Copilot (programa√ß√£o)
- IA criando m√∫sicas e v√≠deos

<br />

## 4.1. Como ela funciona?



1. O modelo √© treinado com uma grande quantidade de dados (textos, imagens, m√∫sicas etc.).
2. Ele aprende padr√µes, estruturas e rela√ß√µes internas nesses dados.
3. Quando recebe um comando (prompt), ele usa o que aprendeu para gerar algo novo que siga padr√µes semelhantes.

> Em geral, os modelos aprendem padr√µes estat√≠sticos dos dados, em vez de copiar conte√∫dos espec√≠ficos. No entanto, a qualidade e diversidade do treinamento influenciam fortemente os resultados.

<br />

## 4.1 Principais modelos de IA Generativa



### üîπ LLM ‚Äî Large Language Models



Modelos de linguagem em larga escala.

<br />

### Como um LLM funciona?



Um **LLM** √© treinado para prever o pr√≥ximo token mais prov√°vel em uma sequ√™ncia. Tokens podem representar palavras inteiras, partes de palavras ou s√≠mbolos.

Pode parecer simples, mas ao repetir isso bilh√µes de vezes durante o treinamento, ele aprende:

- Gram√°tica
- Estilo
- Estrutura textual
- Rela√ß√µes entre conceitos
- Conhecimento geral presente nos dados

<br />

### Passo a passo simplificado



Frase inicial:

> "A intelig√™ncia artificial √©"

O modelo:

1. Analisa todas as palavras anteriores
2. Calcula probabilidades para a pr√≥xima palavra
3. Escolhe a mais prov√°vel (ou uma das mais prov√°veis)
4. Repete o processo palavra por palavra

Isso acontece muito rapidamente.

<br />

### Por que parece que ele "entende"?



Modelos modernos utilizam a arquitetura Transformer, baseada em mecanismos de auto aten√ß√£o (self-attention), que permitem analisar rela√ß√µes entre todas as partes do texto de forma paralelizada.

Isso permite:

- Manter coer√™ncia
- Responder perguntas
- Resumir textos
- Escrever c√≥digo
- Simular di√°logo

**Usos:**

- Modelos como GPT, Claude e Gemini.
- Chatbots
- Escrita autom√°tica
- Programa√ß√£o assistida



### üîπ Redes Advers√°rias Generativas - GAN ‚Äî Generative Adversarial Networks



GANs funcionam com **dois modelos competindo entre si**:

1. **Gerador** ‚Üí cria imagens falsas
2. **Discriminador** ‚Üí tenta identificar se a imagem √© real ou falsa

<br />

### O Processo passo a passo



1. O gerador recebe um vetor de ru√≠do aleat√≥rio como entrada e tenta produzir uma imagem sint√©tica.
2. O discriminador avalia se parece real
3. Se for identificada como falsa, o gerador melhora
4. O processo se repete milhares de vezes

Com o tempo, o gerador fica t√£o bom que cria imagens quase indistingu√≠veis das reais.

<br />

### Analogia simples

> √â como um falsificador tentando enganar um perito. Quanto mais o perito melhora, melhor o falsificador precisa ficar.

<br />

###  Onde GANs s√£o usadas?

- Cria√ß√£o de rostos realistas
- Aumento de resolu√ß√£o de imagens
- Cria√ß√£o de arte digital
- Gera√ß√£o de dados sint√©ticos

<br />

### üîπ VAE ‚Äî Variational Autoencoders



Geram varia√ß√µes realistas de dados.

<br />

### Como funcionam?



Um VAE aprende a **compactar dados em uma representa√ß√£o menor (compress√£o)** e depois reconstru√≠-los.

Ele funciona em duas partes:

1. **Codificador (Encoder)** ‚Üí transforma a entrada em uma representa√ß√£o compacta
2. **Decodificador (Decoder)** ‚Üí reconstr√≥i o dado original

Diferente de autoencoders tradicionais, o VAE aprende uma distribui√ß√£o probabil√≠stica no espa√ßo latente, permitindo gerar novas amostras ao amostrar pontos desse espa√ßo.

> Espa√ßo Latente √© um ‚Äúmapa interno‚Äù criado pelo modelo, no qual informa√ß√µes complexas (como imagens, textos ou √°udios) s√£o representadas de forma reduzida e estruturada.

<br />

### Processo simplificado

1. Recebe uma imagem
2. Comprime para um ‚Äúresumo matem√°tico‚Äù
3. Reconstr√≥i a imagem
4. Aprende a gerar novas vers√µes variando esse resumo

<br />

### Analogia simples



Imagine transformar uma foto em um conjunto de controles:

- Controle de idade
- Controle de express√£o
- Controle de ilumina√ß√£o

Alterando esses controles, o modelo consegue gerar novas imagens semelhantes.

<br />

### Onde VAE s√£o usados?



- Gera√ß√£o de imagens sint√©ticas
- Cria√ß√£o de varia√ß√µes realistas
- Modelagem de dados
- Compress√£o inteligente

<br />

